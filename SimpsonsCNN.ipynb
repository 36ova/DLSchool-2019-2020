{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "SimpsonsCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xtoeDkCYERhI"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrWRKZCfCL16",
        "colab_type": "text"
      },
      "source": [
        "# Simpsons Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk6gp7IcrLPl",
        "colab_type": "text"
      },
      "source": [
        "**Overview**\n",
        "*   The model consists of 7 layers\n",
        "*   Augmentations and learning rate scheduler usage\n",
        "---\n",
        "Kaggle submission private score: 0.97550\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPHe2_R8megi",
        "colab_type": "code",
        "outputId": "f861bbcb-3ab2-4f39-b080-0dbac8e9d20a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import PIL\n",
        "import pickle\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "import random\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from multiprocessing.pool import ThreadPool\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "from matplotlib import colors, pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BNpWawpmrH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "DATA_MODES = ['train', 'val', 'test']\n",
        "RESCALE_SIZE = 224\n",
        "DEVICE = torch.device(\"cuda\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8245f9umP4n",
        "colab_type": "text"
      },
      "source": [
        "####Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S3Y7hKwmU8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmJzGKvFmW5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip -q /content/drive/My\\ Drive/simpsons/data/dataset.zip -d train\n",
        "#!unzip -q /content/drive/My\\ Drive/simpsons/data/testset.zip -d test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL_J27OJERg4",
        "colab_type": "text"
      },
      "source": [
        "#### Dataset construction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ORPkKhzJERg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensor\n",
        "\n",
        "augmentations_chosen = A.Compose([\n",
        "                                  A.HorizontalFlip(0.7), \n",
        "                                  A.RandomContrast(0.7), \n",
        "                                  A.RandomBrightness(0.7),\n",
        "                                  A.RandomBrightnessContrast(0.7), \n",
        "                                  ], p=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "8A5tLfr8ERg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpsonsDataset(Dataset):\n",
        "  def __init__(self, files, mode, augmentations = augmentations_chosen):\n",
        "    super().__init__()\n",
        "    self.files = files\n",
        "    self.mode = mode\n",
        "    self.augmentations = augmentations\n",
        "\n",
        "    if self.mode not in DATA_MODES:\n",
        "      print(f'wrong mode: {self.mode}')\n",
        "      raise NameError\n",
        "\n",
        "    self.len_ = len(self.files)\n",
        "    self.label_encoder = LabelEncoder()\n",
        "\n",
        "    if self.mode != 'test':\n",
        "      self.labels = [path.parent.name for path in self.files]\n",
        "      self.label_encoder.fit(self.labels)\n",
        "\n",
        "      with open('label_encoder.pkl', 'wb') as le_dump:\n",
        "        pickle.dump(self.label_encoder, le_dump)\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len_\n",
        "\n",
        "  def load_sample(self, file):\n",
        "    image = Image.open(file)\n",
        "    image.load()\n",
        "    return image\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])                                \n",
        "    ])\n",
        "\n",
        "    x = self.load_sample(self.files[index])\n",
        "    x = self._prepare_sample(x)\n",
        "    x = np.array(x / 255, dtype='float32')\n",
        "    x = transform(x)\n",
        "  \n",
        "    if self.mode == 'test':\n",
        "      return x\n",
        "    else:\n",
        "\n",
        "      #applying augmentations \n",
        "      \n",
        "      augmented = self.augmentations(image = x.numpy())\n",
        "      label = self.labels[index]\n",
        "      label_id = self.label_encoder.transform([label])\n",
        "      y = label_id.item()\n",
        "      return x, y\n",
        "\n",
        "  def _prepare_sample(self, image):\n",
        "    image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n",
        "    return np.array(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNWhhUA7qRUt",
        "colab_type": "text"
      },
      "source": [
        "**Val/train split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Lao7LfXRERhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DIR = Path('/content/train/train')\n",
        "TEST_DIR = Path('/content/test/testset/testset')\n",
        "\n",
        "train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n",
        "test_files = sorted(list(TEST_DIR.rglob('*.jpg')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oTFX7-kvERhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_val_labels = [path.parent.name for path in train_val_files]\n",
        "train_files, val_files = train_test_split(train_val_files, test_size=0.3, \\\n",
        "                                          stratify=train_val_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ErZKWGOMERhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = SimpsonsDataset(val_files, mode='val')\n",
        "train_dataset = SimpsonsDataset(train_files, mode='train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtoeDkCYERhI",
        "colab_type": "text"
      },
      "source": [
        "####Exploring the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9ZkA_H0SERhJ",
        "colab_type": "code",
        "outputId": "2414dc76-40a3-405b-9574-bd5f3d0a2415",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def imshow(img, title=None, plt_ax=plt, default=False):\n",
        "  img = img.numpy().transpose((1, 2, 0))\n",
        "  mean = np.array([0.485, 0.456, 0.406])\n",
        "  std = np.array([0.229, 0.224, 0.225])\n",
        "  img = std * img + mean\n",
        "  img = np.clip(img, 0, 1)\n",
        "  plt_ax.imshow(img)\n",
        "  if title is not None:\n",
        "    plt_ax.set_title(title)\n",
        "  plt_ax.grid(False)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(10,10), sharex=True, sharey=True)\n",
        "\n",
        "for fig_x in ax.flatten():\n",
        "    random_characters = int(np.random.uniform(0,1000))\n",
        "    im_val, label = val_dataset[random_characters]\n",
        "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
        "                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
        "    imshow(im_val.data.cpu(), \\\n",
        "          title=img_label,plt_ax=fig_x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef imshow(img, title=None, plt_ax=plt, default=False):\\n  img = img.numpy().transpose((1, 2, 0))\\n  mean = np.array([0.485, 0.456, 0.406])\\n  std = np.array([0.229, 0.224, 0.225])\\n  img = std * img + mean\\n  img = np.clip(img, 0, 1)\\n  plt_ax.imshow(img)\\n  if title is not None:\\n    plt_ax.set_title(title)\\n  plt_ax.grid(False)\\n\\n\\nfig, ax = plt.subplots(nrows=3, ncols=3, figsize=(10,10), sharex=True, sharey=True)\\n\\nfor fig_x in ax.flatten():\\n    random_characters = int(np.random.uniform(0,1000))\\n    im_val, label = val_dataset[random_characters]\\n    img_label = \" \".join(map(lambda x: x.capitalize(),                val_dataset.label_encoder.inverse_transform([label])[0].split(\\'_\\')))\\n    imshow(im_val.data.cpu(),           title=img_label,plt_ax=fig_x)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhN5tWXoERhP",
        "colab_type": "text"
      },
      "source": [
        "####Building the model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqQB0cumC-Th",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvModel(nn.Module):\n",
        "  \n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential( # 224 222 111\n",
        "            nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv2 = nn.Sequential( # 111 109 54\n",
        "            nn.Conv2d(in_channels=8, out_channels=32, kernel_size=3), \n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), \n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv3 = nn.Sequential( # 54 52 26\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv4 = nn.Sequential( # 26 24 12\n",
        "            nn.Conv2d(in_channels=64, out_channels=96, kernel_size=3),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.conv5 = nn.Sequential( # 12 10 5\n",
        "            nn.Conv2d(in_channels=96, out_channels=164, kernel_size=3),\n",
        "            nn.BatchNorm2d(164),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.fc1 = nn.Sequential( # 4100\n",
        "            nn.Linear(5 * 5 * 164, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.fc2 = nn.Sequential( # 1024\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU()\n",
        "        )        \n",
        "        self.out = nn.Linear(1024, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = x.view(-1, 5 * 5 * 164)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        logits = self.out(x)\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nBn7OzqbERhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit_epoch(model, train_loader, criterion, optimizer):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    processed_data = 0\n",
        "  \n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        preds = torch.argmax(outputs, 1)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        processed_data += inputs.size(0)\n",
        "              \n",
        "    train_loss = running_loss / processed_data\n",
        "    train_acc = running_corrects.cpu().numpy() / processed_data\n",
        "    return train_loss, train_acc\n",
        "  \n",
        "def eval_epoch(model, val_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    processed_size = 0\n",
        "\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs = inputs.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "\n",
        "        with torch.set_grad_enabled(False):\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        processed_size += inputs.size(0)\n",
        "    val_loss = running_loss / processed_size\n",
        "    val_acc = running_corrects.double() / processed_size\n",
        "    return val_loss, val_acc\n",
        "  \n",
        "def train(train_files, val_files, model, epochs, batch_size, scheduler):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    history = []\n",
        "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
        "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n",
        "\n",
        "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
        "      \n",
        "        for epoch in range(epochs):\n",
        "            \n",
        "            train_loss, train_acc = fit_epoch(model, train_loader, criterion, optimizer_ft)\n",
        "\n",
        "            scheduler.step() # changing learning rate\n",
        "\n",
        "            print(\"loss\", train_loss)\n",
        "            \n",
        "            val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n",
        "            history.append((train_loss, train_acc, val_loss, val_acc))\n",
        "            \n",
        "            pbar_outer.update(1)\n",
        "            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n",
        "                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
        "            \n",
        "    return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zb4fhEV_ERhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, test_loader):\n",
        "    with torch.no_grad():\n",
        "        logits = []\n",
        "    \n",
        "        for inputs in test_loader:\n",
        "            inputs = inputs.to(DEVICE)\n",
        "            model.eval()\n",
        "            outputs = model(inputs).cpu()\n",
        "            logits.append(outputs)\n",
        "            \n",
        "    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n",
        "    return probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xOAgIA9FERhY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_classes = len(np.unique(train_val_labels))\n",
        "model = ConvModel(n_classes).to(DEVICE)\n",
        "\n",
        "optimizer_ft = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIQGisGqERha",
        "colab_type": "text"
      },
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "V-O4z2_hERhi",
        "colab_type": "code",
        "outputId": "c4d680a9-6f83-4221-9d10-fe90eb18b9db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        }
      },
      "source": [
        "history = train(train_dataset, val_dataset, model=model, epochs=10, batch_size=32, scheduler=exp_lr_scheduler)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\repoch:   0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss 1.6109317727587795\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  10%|█         | 1/10 [01:55<17:21, 115.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 001 train_loss: 1.6109     val_loss 1.0997 train_acc 0.5584 val_acc 0.6861\n",
            "loss 0.9906811145379797\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  20%|██        | 2/10 [03:52<15:27, 115.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 002 train_loss: 0.9907     val_loss 0.8632 train_acc 0.7165 val_acc 0.7540\n",
            "loss 0.5911282525874971\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  30%|███       | 3/10 [05:48<13:31, 115.96s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 003 train_loss: 0.5911     val_loss 0.7424 train_acc 0.8323 val_acc 0.7992\n",
            "loss 0.3687459219633284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  40%|████      | 4/10 [07:43<11:35, 115.88s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 004 train_loss: 0.3687     val_loss 0.6261 train_acc 0.8907 val_acc 0.8382\n",
            "loss 0.2207185193588162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  50%|█████     | 5/10 [09:41<09:42, 116.46s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 005 train_loss: 0.2207     val_loss 0.9041 train_acc 0.9331 val_acc 0.8132\n",
            "loss 0.17909835800167515\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  60%|██████    | 6/10 [11:39<07:47, 116.82s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 006 train_loss: 0.1791     val_loss 0.8249 train_acc 0.9440 val_acc 0.8245\n",
            "loss 0.11525238679791484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  70%|███████   | 7/10 [13:35<05:50, 116.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 007 train_loss: 0.1153     val_loss 0.8360 train_acc 0.9674 val_acc 0.8333\n",
            "loss 0.0250318330036799\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  80%|████████  | 8/10 [15:31<03:53, 116.52s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 008 train_loss: 0.0250     val_loss 0.6333 train_acc 0.9932 val_acc 0.8748\n",
            "loss 0.0031257925004153195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch:  90%|█████████ | 9/10 [17:28<01:56, 116.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 009 train_loss: 0.0031     val_loss 0.6452 train_acc 0.9997 val_acc 0.8756\n",
            "loss 0.0017331542719096695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 100%|██████████| 10/10 [19:24<00:00, 116.55s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 010 train_loss: 0.0017     val_loss 0.6626 train_acc 0.9998 val_acc 0.8769\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZwGOt-94ERhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc, val_loss, val_acc = zip(*history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UtWjn7CZERho",
        "colab_type": "code",
        "outputId": "068a27a2-7c1e-4f4a-e68a-b1b04d138e06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "plt.figure(figsize=(16, 3))\n",
        "plt.plot(loss, label=\"train_loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAADQCAYAAAAzv/1CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1152x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cASaCz5wM0kM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_one_sample(model, inputs, device=DEVICE):\n",
        "    with torch.no_grad():\n",
        "        inputs = inputs.to(device)\n",
        "        model.eval()\n",
        "        logit = model(inputs).cpu()\n",
        "        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\n",
        "    return probs\n",
        "\n",
        "def Get_F1_Score(model):\n",
        "    label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "    random_characters = int(np.random.uniform(0,1000))\n",
        "    ex_img, true_label = val_dataset[random_characters]\n",
        "    probs_im = predict_one_sample(model, ex_img.unsqueeze(0))\n",
        "    idxs = list(map(int, np.random.uniform(0,1000, 20)))\n",
        "    imgs = [val_dataset[id][0].unsqueeze(0) for id in idxs]\n",
        "\n",
        "    probs_ims = predict(model, imgs)\n",
        "    y_pred = np.argmax(probs_ims,-1)\n",
        "\n",
        "    actual_labels = [val_dataset[id][1] for id in idxs]\n",
        "\n",
        "    preds_class = [label_encoder.classes_[i] for i in y_pred]\n",
        "    preds_class_numbers = [val_dataset.label_encoder.transform([name])[0] for name in preds_class] \n",
        "\n",
        "    return np.mean(f1_score(actual_labels, preds_class_numbers, average = None))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcviQpUv4zgM",
        "colab_type": "code",
        "outputId": "fcd01a6d-5386-43b1-9b3c-8341c3d57758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Get_F1_Score(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.958974358974359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrDViENGERhr",
        "colab_type": "text"
      },
      "source": [
        "#### Submission\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aM3m1W0MERhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))\n",
        "\n",
        "test_dataset = SimpsonsDataset(test_files, mode=\"test\")\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\n",
        "probs = predict(model, test_loader)\n",
        "\n",
        "preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\n",
        "test_filenames = [path.name for path in test_dataset.files]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "08DeDvSZERhu",
        "colab_type": "code",
        "outputId": "d1d3d1f7-a7a6-41a1-bf99-15a1db0c8eaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "submit = pd.DataFrame({'Id': test_filenames, 'Expected': preds})\n",
        "submit.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Expected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>img0.jpg</td>\n",
              "      <td>nelson_muntz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>img1.jpg</td>\n",
              "      <td>bart_simpson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>img10.jpg</td>\n",
              "      <td>ned_flanders</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>img100.jpg</td>\n",
              "      <td>chief_wiggum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>img101.jpg</td>\n",
              "      <td>apu_nahasapeemapetilon</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Id                Expected\n",
              "0    img0.jpg            nelson_muntz\n",
              "1    img1.jpg            bart_simpson\n",
              "2   img10.jpg            ned_flanders\n",
              "3  img100.jpg            chief_wiggum\n",
              "4  img101.jpg  apu_nahasapeemapetilon"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vaAQmAmiERhy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}